## Inpainting Web App Project

This project is an interactive web application for advanced image editing using AI. It enables users to swap out the background of a subject in an image and replace it with a new, AI-generated background based on a text prompt. The app leverages state-of-the-art models for segmentation and generative inpainting.

### Features
- Upload your own image and select the subject using point-based segmentation (SAM).
- Automatically generate a segmentation mask for the subject.
- Remove the original background and replace it with a new one generated by Stable Diffusion XL via a text prompt.
- Optionally specify negative prompts to improve output quality.
- Visualize the original image, mask, and final result side-by-side.
- Interactive web interface for easy experimentation.

### Technologies Used
- **Python**
- **Jupyter Notebook** for prototyping and interactive development
- **Segment Anything Model (SAM)** for image segmentation
- **Diffusers Library** for Stable Diffusion XL inpainting
- **Pillow (PIL)** for image processing
- **Torch** for model inference

### Setup Instructions
1. Clone the repository and navigate to the project folder.
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. (Optional) For Apple Silicon, ensure you have the latest PyTorch with MPS support.
4. Run the Jupyter notebook and follow the instructions in `project.ipynb`.

### Usage
1. Open `project.ipynb` in Jupyter.
2. Execute the cells to load models and test segmentation/inpainting.
3. Use the interactive app cell to upload your own images and try different prompts.
4. View the results and experiment with different settings.

### Example Workflow
1. Upload an image (e.g., a car).
2. Select points on the subject to generate a mask.
3. Enter a text prompt (e.g., "a car driving on Mars. Studio lights, 1970s").
4. The app generates a new background and displays the result.
